{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MyChatBot_Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RedaGrace/ChatBot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UsOJVv49jOu"
      },
      "source": [
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcAAF1wf9jOw",
        "outputId": "02b4e409-4760-4c1d-cdbb-04c8fc989dab"
      },
      "source": [
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRNSQ5019jOx"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "intents = pd.read_json('intents.json')\n",
        "\n",
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_letters = ['!', '?', ',', '.']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsMELDaF9jOx"
      },
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        word = nltk.word_tokenize(pattern)\n",
        "        words.extend(word)\n",
        "        documents.append((word, intent['tag']))\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or7IO3AO9jOx",
        "outputId": "1b637366-4d2a-4624-9770-dbe1d23c4141"
      },
      "source": [
        "documents[10:20]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['Good', 'Evening'], 'greeting'),\n",
              " (['hey'], 'greeting'),\n",
              " (['how', 'are'], 'greeting'),\n",
              " (['How', 'are', 'you', 'doing'], 'greeting'),\n",
              " (['Good', 'afternoon'], 'greeting'),\n",
              " (['Good', 'day'], 'greeting'),\n",
              " ([], 'greeting'),\n",
              " (['Bye'], 'goodbye'),\n",
              " (['See', 'you', 'later'], 'goodbye'),\n",
              " (['Goodbye'], 'goodbye')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7S4QN_I9jOx",
        "outputId": "0b9ee819-740b-4ac9-be15-77e117795344"
      },
      "source": [
        "words[0:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mRjlVit9jOy"
      },
      "source": [
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_letters]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "pickle.dump(words, open('words.pkl', 'wb'))\n",
        "pickle.dump(classes, open('classes.pkl', 'wb'))\n",
        "\n",
        "training = []\n",
        "output_empty = [0] * len(classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Oo_33W9jOy"
      },
      "source": [
        "for doc in documents:\n",
        "    bag = []\n",
        "    word_patterns = doc[0]\n",
        "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
        "    for word in words:\n",
        "        bag.append(1) if word in word_patterns else bag.append(0)\n",
        "\n",
        "        output_row = list(output_empty)\n",
        "        output_row[classes.index(doc[1])] = 1\n",
        "        training.append([bag, output_row])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7JOHzPE9jOy",
        "outputId": "86d37774-c4f5-4f17-802d-2cd1a3f7b2a2"
      },
      "source": [
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "train_x = list(training[:, 0])\n",
        "train_y = list(training[:, 1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZqauNuc9jOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9eef97-7f80-4d62-e604-f3780fee9761"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "quit\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=20, batch_size=50, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.9930 - accuracy: 0.7398\n",
            "Epoch 2/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.2487 - accuracy: 0.9180\n",
            "Epoch 3/20\n",
            "11097/11097 [==============================] - 32s 3ms/step - loss: 0.1903 - accuracy: 0.9357\n",
            "Epoch 4/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.1611 - accuracy: 0.9451\n",
            "Epoch 5/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.1430 - accuracy: 0.9510\n",
            "Epoch 6/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.1309 - accuracy: 0.9546\n",
            "Epoch 7/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.1222 - accuracy: 0.9572\n",
            "Epoch 8/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.1136 - accuracy: 0.9597\n",
            "Epoch 9/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.1079 - accuracy: 0.9616\n",
            "Epoch 10/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.1034 - accuracy: 0.9631\n",
            "Epoch 11/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.0992 - accuracy: 0.9646\n",
            "Epoch 12/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.0948 - accuracy: 0.9659\n",
            "Epoch 13/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.0919 - accuracy: 0.9670\n",
            "Epoch 14/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.0871 - accuracy: 0.9685\n",
            "Epoch 15/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.0865 - accuracy: 0.9687\n",
            "Epoch 16/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.0819 - accuracy: 0.9702\n",
            "Epoch 17/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.0800 - accuracy: 0.9708\n",
            "Epoch 18/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.0786 - accuracy: 0.9714\n",
            "Epoch 19/20\n",
            "11097/11097 [==============================] - 33s 3ms/step - loss: 0.0773 - accuracy: 0.9717\n",
            "Epoch 20/20\n",
            "11097/11097 [==============================] - 34s 3ms/step - loss: 0.0758 - accuracy: 0.9722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5at0bz9jOz"
      },
      "source": [
        "model.save('chatbot_model.h5', hist)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX8dK39G9jOz"
      },
      "source": [
        "words = pickle.load(open('words.pkl', 'rb'))\n",
        "classes = pickle.load(open('classes.pkl', 'rb'))\n",
        "model = load_model('chatbot_model.h5')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl2-ABnR9jO0"
      },
      "source": [
        "def _clean_up_sentence(sentence):\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Awy4ykr9jO0"
      },
      "source": [
        "def _bag_of_words(sentence, words):\n",
        "    sentence_words = _clean_up_sentence(sentence)\n",
        "    bag = [0] * len(words)\n",
        "    for s in sentence_words:\n",
        "        for i, word in enumerate(words):\n",
        "            if word == s:\n",
        "                bag[i] = 1\n",
        "    return np.array(bag)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk0JMF0c9jO0"
      },
      "source": [
        "def _predict_class(sentence):\n",
        "    p = _bag_of_words(sentence, words)\n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    ERROR_THRESHOLD = 0.1\n",
        "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
        "    return return_list"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYKu6nRX9jO0"
      },
      "source": [
        "def _get_response(ints, intents_json):\n",
        "    try:\n",
        "        tag = ints[0]['intent']\n",
        "        list_of_intents = intents_json['intents']\n",
        "        for i in list_of_intents:\n",
        "            if i['tag']  == tag:\n",
        "                result = random.choice(i['responses'])\n",
        "                break\n",
        "    except IndexError:\n",
        "        result = \"I don't understand!\"\n",
        "    return result"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNryqSVC9jO0"
      },
      "source": [
        "def chat():\n",
        "    print(\"Hi, How can i help you ?\")\n",
        "    while True:\n",
        "        message = input(\"You: \")\n",
        "        if message.lower() == 'quit':\n",
        "            break\n",
        "        ints = _predict_class(message)\n",
        "        res = _get_response(ints, intents)\n",
        "        print(res)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaLxAGJA9jO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e31a8d5-3996-4794-8c3f-27697fab894a"
      },
      "source": [
        "chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, How can i help you ?\n",
            "You: hi\n",
            "Good to see you again\n",
            "You: how to register to the university?\n",
            "You can join the university after fulfilling the conditions by evaluating the required papers in the affairs department and awaiting admission.\n",
            "You: what if i missed an exam\n",
            "The total of what you got from the pre-final exam marks is recorded for you, and in the event that you submit an excuse accepted by the Dean of the College within three days of the date of the exam, then you will record an incomplete mark, and you can apply for the final exam again, up to the end of the third week of the immediately following semester .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ9EGNMh9jO1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}